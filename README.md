# Web Crawler Frontend

This project provides the user interface for interacting with the web crawler backend, allowing users to input URLs and extract links from websites. It's built using Next.js, TypeScript, Tailwind CSS, and Redux for state management.

## Installation

To install the project, follow these steps:

1. **Clone the Repository**: Clone the project repository to your local machine using the following command:

    > git clone https://github.com/dresnite/web-crawler-frontend

2. **Install Dependencies**: Navigate into the project directory and install the necessary dependencies using npm:

    > npm install


3. **Set Environment Variables**: Before running the project, you need to set up the `BACKEND_URL` environment variable. This variable should point to the URL of the backend server. 

4. **Start the Development Server**: Once the environment variable is set, you can start the development server using the following command:

    > npm run dev


## Dependencies

The frontend project relies on the following technologies and libraries:

- **Next.js**: Framework for building React applications with server-side rendering.
- **TypeScript**: Typed superset of JavaScript.
- **Tailwind CSS**: Utility-first CSS framework for styling the application.
- **Redux**: State management library for managing application state.

## Backend Dependency

Please note that this frontend project requires the web crawler backend (https://github.com/dresnite/web-crawler-backend) to be running properly. Ensure that the backend server is set up and running before using the frontend application.

Feel free to reach out if you have any questions or need further assistance!

---

**Note**: For detailed information on how to use the backend server, refer to the [backend README](https://github.com/dresnite/web-crawler-backend).


